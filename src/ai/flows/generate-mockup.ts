// This is an autogenerated file from Firebase Studio.
'use server';

/**
 * @fileOverview A flow that generates a logo mockup based on a text prompt and uploaded logo.
 *
 * - generateMockup - A function that handles the mockup generation process.
 * - GenerateMockupInput - The input type for the generateMockup function.
 * - GenerateMockupOutput - The return type for the generateMockup function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const GenerateMockupInputSchema = z.object({
  logoDataUri: z
    .string()
    .describe(
      "A transparent logo (PNG) as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:image/png;base64,<encoded_data>'."
    ),
  prompt: z.string().describe('A text prompt describing the desired mockup scene.'),
});
export type GenerateMockupInput = z.infer<typeof GenerateMockupInputSchema>;

const GenerateMockupOutputSchema = z.object({
  mockupDataUri: z
    .string()
    .describe(
      'The generated mockup as a data URI that must include a MIME type and use Base64 encoding. Expected format: \'data:<mimetype>;base64,<encoded_data>\'.' // escaping the single quote inside the string
    ),
});
export type GenerateMockupOutput = z.infer<typeof GenerateMockupOutputSchema>;

export async function generateMockup(input: GenerateMockupInput): Promise<GenerateMockupOutput> {
  return generateMockupFlow(input);
}

const prompt = ai.definePrompt({
  name: 'generateMockupPrompt',
  input: {schema: GenerateMockupInputSchema},
  output: {schema: GenerateMockupOutputSchema},
  prompt: `Generate a realistic mockup of the provided logo in the scene described by the prompt.\n\nLogo: {{media url=logoDataUri}}\n\nScene Description: {{{prompt}}}`,
});

const generateMockupFlow = ai.defineFlow(
  {
    name: 'generateMockupFlow',
    inputSchema: GenerateMockupInputSchema,
    outputSchema: GenerateMockupOutputSchema,
  },
  async input => {
    const {media} = await ai.generate({
      // IMPORTANT: ONLY the googleai/gemini-2.0-flash-preview-image-generation model is able to generate images. You MUST use exactly this model to generate images.
      model: 'googleai/gemini-2.0-flash-preview-image-generation',

      prompt: [
        {media: {url: input.logoDataUri}},
        {text: input.prompt},
      ],

      config: {
        responseModalities: ['TEXT', 'IMAGE'], // MUST provide both TEXT and IMAGE, IMAGE only won't work
      },
    });
    return {mockupDataUri: media.url!};
  }
);
